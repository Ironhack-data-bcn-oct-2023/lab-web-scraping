{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Lab\n",
    "\n",
    "You will find in this notebook some scrapy exercises to practise your scraping skills.\n",
    "\n",
    "**Tips:**\n",
    "\n",
    "- Check the response status code for each request to ensure you have obtained the intended contennt.\n",
    "- Print the response text in each request to understand the kind of info you are getting and its format.\n",
    "- Check for patterns in the response text to extract the data/info requested in each question.\n",
    "- Visit each url and take a look at its source through Chrome DevTools. You'll need to identify the html tags, special class names etc. used for the html content you are expected to extract."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Requests library](http://docs.python-requests.org/en/master/#the-user-guide) documentation \n",
    "- [Beautiful Soup Doc](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "- [Urllib](https://docs.python.org/3/library/urllib.html#module-urllib)\n",
    "- [re lib](https://docs.python.org/3/library/re.html)\n",
    "- [lxml lib](https://lxml.de/)\n",
    "- [Scrapy](https://scrapy.org/)\n",
    "- [List of HTTP status codes](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes)\n",
    "- [HTML basics](http://www.simplehtmlguide.com/cheatsheet.php)\n",
    "- [CSS basics](https://www.cssbasics.com/#page_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below are the libraries and modules you may need. `requests`,  `BeautifulSoup` and `pandas` are imported for you. If you prefer to use additional libraries feel free to uncomment them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "# from pprint import pprint\n",
    "# from lxml import html\n",
    "# from lxml.html import fromstring\n",
    "# import urllib.request\n",
    "from urllib.request import urlopen\n",
    "# import random\n",
    "import re\n",
    "# import scrapy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download, parse (using BeautifulSoup), and print the content from the Trending Developers page from GitHub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://github.com/trending/developers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = requests.get('https://github.com/trending/developers')\n",
    "res\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = res.content\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h1 class=\"h3 lh-condensed\">\n",
       " <a class=\"Link\" data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"TRENDING_DEVELOPERS_PAGE\",\"click_target\":\"OWNER\",\"click_visual_representation\":\"TRENDING_DEVELOPER\",\"actor_id\":null,\"record_id\":388154,\"originating_url\":\"https://github.com/trending/developers\",\"user_id\":null}}' data-hydro-click-hmac=\"6f07ba99141b0703aa0e0003ae36e5b976105817d8e14043bd70248799106ec2\" data-view-component=\"true\" href=\"/wsxiaoys\">\n",
       "             Meng Zhang\n",
       " </a> </h1>,\n",
       " <h1 class=\"h3 lh-condensed\">\n",
       " <a class=\"Link\" data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"TRENDING_DEVELOPERS_PAGE\",\"click_target\":\"OWNER\",\"click_visual_representation\":\"TRENDING_DEVELOPER\",\"actor_id\":null,\"record_id\":53356347,\"originating_url\":\"https://github.com/trending/developers\",\"user_id\":null}}' data-hydro-click-hmac=\"8727d185f53f762334cfdc2ea5043cd4545e05f0bd0bd486e3e5d85a2f414d17\" data-view-component=\"true\" href=\"/azure-sdk\">\n",
       "             Azure SDK Bot\n",
       " </a> </h1>,\n",
       " <h1 class=\"h3 lh-condensed\">\n",
       " <a class=\"Link\" data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"TRENDING_DEVELOPERS_PAGE\",\"click_target\":\"OWNER\",\"click_visual_representation\":\"TRENDING_DEVELOPER\",\"actor_id\":null,\"record_id\":216089,\"originating_url\":\"https://github.com/trending/developers\",\"user_id\":null}}' data-hydro-click-hmac=\"ac5c25d23e8a1e81905e2348b9417dafad1112a36a744ade32ece9a4cae913ae\" data-view-component=\"true\" href=\"/AliSoftware\">\n",
       "             Olivier Halligon\n",
       " </a> </h1>,\n",
       " <h1 class=\"h3 lh-condensed\">\n",
       " <a class=\"Link\" data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"TRENDING_DEVELOPERS_PAGE\",\"click_target\":\"OWNER\",\"click_visual_representation\":\"TRENDING_DEVELOPER\",\"actor_id\":null,\"record_id\":8177701,\"originating_url\":\"https://github.com/trending/developers\",\"user_id\":null}}' data-hydro-click-hmac=\"8862a9fb5fa535c56d713b62299bd8dbec258ae086819c7cd34e915c3d4fb623\" data-view-component=\"true\" href=\"/odow\">\n",
       "             Oscar Dowson\n",
       " </a> </h1>,\n",
       " <h1 class=\"h3 lh-condensed\">\n",
       " <a class=\"Link\" data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"TRENDING_DEVELOPERS_PAGE\",\"click_target\":\"OWNER\",\"click_visual_representation\":\"TRENDING_DEVELOPER\",\"actor_id\":null,\"record_id\":438920,\"originating_url\":\"https://github.com/trending/developers\",\"user_id\":null}}' data-hydro-click-hmac=\"c68aacbc5b150c675fad23800be8f3d4d0fbda52a7cd1c10a8f486709bad4618\" data-view-component=\"true\" href=\"/fatih\">\n",
       "             Fatih Arslan\n",
       " </a> </h1>,\n",
       " <h1 class=\"h3 lh-condensed\">\n",
       " <a class=\"Link\" data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"TRENDING_DEVELOPERS_PAGE\",\"click_target\":\"OWNER\",\"click_visual_representation\":\"TRENDING_DEVELOPER\",\"actor_id\":null,\"record_id\":173661,\"originating_url\":\"https://github.com/trending/developers\",\"user_id\":null}}' data-hydro-click-hmac=\"e5f8b488975347353146deff5d76f57f9c5823c58166af008ff3dade354f7a3a\" data-view-component=\"true\" href=\"/kripken\">\n",
       "             Alon Zakai\n",
       " </a> </h1>,\n",
       " <h1 class=\"h3 lh-condensed\">\n",
       " <a class=\"Link\" data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"TRENDING_DEVELOPERS_PAGE\",\"click_target\":\"OWNER\",\"click_visual_representation\":\"TRENDING_DEVELOPER\",\"actor_id\":null,\"record_id\":5495193,\"originating_url\":\"https://github.com/trending/developers\",\"user_id\":null}}' data-hydro-click-hmac=\"f29d305331202cf3b90c8b0761b741d320e8262211bf8bc8c7c38abe489e6916\" data-view-component=\"true\" href=\"/awaelchli\">\n",
       "             Adrian Wälchli\n",
       " </a> </h1>,\n",
       " <h1 class=\"h3 lh-condensed\">\n",
       " <a class=\"Link\" data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"TRENDING_DEVELOPERS_PAGE\",\"click_target\":\"OWNER\",\"click_visual_representation\":\"TRENDING_DEVELOPER\",\"actor_id\":null,\"record_id\":5889274,\"originating_url\":\"https://github.com/trending/developers\",\"user_id\":null}}' data-hydro-click-hmac=\"0bb77c6cf7591a91783a79dafcb3d943a698a7fab4b9946802f996b1808b6bf7\" data-view-component=\"true\" href=\"/Vectorized\">\n",
       "             Vectorized\n",
       " </a> </h1>,\n",
       " <h1 class=\"h3 lh-condensed\">\n",
       " <a class=\"Link\" data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"TRENDING_DEVELOPERS_PAGE\",\"click_target\":\"OWNER\",\"click_visual_representation\":\"TRENDING_DEVELOPER\",\"actor_id\":null,\"record_id\":1629785,\"originating_url\":\"https://github.com/trending/developers\",\"user_id\":null}}' data-hydro-click-hmac=\"9d8877890ce57c91e5229288b50ebfc009df634258615bd3d1b2cd580f4981e7\" data-view-component=\"true\" href=\"/JonnyBurger\">\n",
       "             Jonny Burger\n",
       " </a> </h1>,\n",
       " <h1 class=\"h3 lh-condensed\">\n",
       " <a class=\"Link\" data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"TRENDING_DEVELOPERS_PAGE\",\"click_target\":\"OWNER\",\"click_visual_representation\":\"TRENDING_DEVELOPER\",\"actor_id\":null,\"record_id\":14142,\"originating_url\":\"https://github.com/trending/developers\",\"user_id\":null}}' data-hydro-click-hmac=\"8c55eca6f5920e69c9f6e1ab460e3a8951a31a7a7876663e1cecefaa94ef292b\" data-view-component=\"true\" href=\"/killme2008\">\n",
       "             dennis zhuang\n",
       " </a> </h1>,\n",
       " <h1 class=\"h3 lh-condensed\">\n",
       " <a class=\"Link\" data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"TRENDING_DEVELOPERS_PAGE\",\"click_target\":\"OWNER\",\"click_visual_representation\":\"TRENDING_DEVELOPER\",\"actor_id\":null,\"record_id\":1580956,\"originating_url\":\"https://github.com/trending/developers\",\"user_id\":null}}' data-hydro-click-hmac=\"419d477e79113df6b3ac09fb2c8b3d44a08c29d3345903bb5a32cd6078b6dbed\" data-view-component=\"true\" href=\"/chenrui333\">\n",
       "             Rui Chen\n",
       " </a> </h1>,\n",
       " <h1 class=\"h3 lh-condensed\">\n",
       " <a class=\"Link\" data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"TRENDING_DEVELOPERS_PAGE\",\"click_target\":\"OWNER\",\"click_visual_representation\":\"TRENDING_DEVELOPER\",\"actor_id\":null,\"record_id\":1309177,\"originating_url\":\"https://github.com/trending/developers\",\"user_id\":null}}' data-hydro-click-hmac=\"da78484eb9f5bc81421275d60ba31a7fb16a56c1eb93a4363627691fa0417b03\" data-view-component=\"true\" href=\"/charliermarsh\">\n",
       "             Charlie Marsh\n",
       " </a> </h1>,\n",
       " <h1 class=\"h3 lh-condensed\">\n",
       " <a class=\"Link\" data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"TRENDING_DEVELOPERS_PAGE\",\"click_target\":\"OWNER\",\"click_visual_representation\":\"TRENDING_DEVELOPER\",\"actor_id\":null,\"record_id\":210737,\"originating_url\":\"https://github.com/trending/developers\",\"user_id\":null}}' data-hydro-click-hmac=\"2fcad36f6831465335b27dc51e29eadc6eed1d454cb5a56a5e5099f4a5ebf150\" data-view-component=\"true\" href=\"/imjasonh\">\n",
       "             Jason Hall\n",
       " </a> </h1>,\n",
       " <h1 class=\"h3 lh-condensed\">\n",
       " <a class=\"Link\" data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"TRENDING_DEVELOPERS_PAGE\",\"click_target\":\"OWNER\",\"click_visual_representation\":\"TRENDING_DEVELOPER\",\"actor_id\":null,\"record_id\":27354907,\"originating_url\":\"https://github.com/trending/developers\",\"user_id\":null}}' data-hydro-click-hmac=\"3e9c367dc3c948f712749863989c5f55fb9c8137c35742ad483c4e5919c546a0\" data-view-component=\"true\" href=\"/shahednasser\">\n",
       "             Shahed Nasser\n",
       " </a> </h1>,\n",
       " <h1 class=\"h3 lh-condensed\">\n",
       " <a class=\"Link\" data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"TRENDING_DEVELOPERS_PAGE\",\"click_target\":\"OWNER\",\"click_visual_representation\":\"TRENDING_DEVELOPER\",\"actor_id\":null,\"record_id\":1046063,\"originating_url\":\"https://github.com/trending/developers\",\"user_id\":null}}' data-hydro-click-hmac=\"07239246114508055bb7eb27156690dced75dded8aea9e00ff23fc891c094de8\" data-view-component=\"true\" href=\"/joshlf\">\n",
       "             Joshua Liebow-Feeser\n",
       " </a> </h1>,\n",
       " <h1 class=\"h3 lh-condensed\">\n",
       " <a class=\"Link\" data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"TRENDING_DEVELOPERS_PAGE\",\"click_target\":\"OWNER\",\"click_visual_representation\":\"TRENDING_DEVELOPER\",\"actor_id\":null,\"record_id\":12937446,\"originating_url\":\"https://github.com/trending/developers\",\"user_id\":null}}' data-hydro-click-hmac=\"a0334adcb667c12e619621d82e9da120767d617e0ebf6023709b505cc7a6ed82\" data-view-component=\"true\" href=\"/pngwn\">\n",
       "             pngwn\n",
       " </a> </h1>,\n",
       " <h1 class=\"h3 lh-condensed\">\n",
       " <a class=\"Link\" data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"TRENDING_DEVELOPERS_PAGE\",\"click_target\":\"OWNER\",\"click_visual_representation\":\"TRENDING_DEVELOPER\",\"actor_id\":null,\"record_id\":10676103,\"originating_url\":\"https://github.com/trending/developers\",\"user_id\":null}}' data-hydro-click-hmac=\"9922285bb93ed4f4bdab0fa5fa8dc9033894b1a15d7a7ec43c2448935db40828\" data-view-component=\"true\" href=\"/stas00\">\n",
       "             Stas Bekman\n",
       " </a> </h1>,\n",
       " <h1 class=\"h3 lh-condensed\">\n",
       " <a class=\"Link\" data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"TRENDING_DEVELOPERS_PAGE\",\"click_target\":\"OWNER\",\"click_visual_representation\":\"TRENDING_DEVELOPER\",\"actor_id\":null,\"record_id\":82342,\"originating_url\":\"https://github.com/trending/developers\",\"user_id\":null}}' data-hydro-click-hmac=\"a8324adccb393983e3bd3ded846d76e4f0800f7f6e85c16e72dfc20163fbc8fd\" data-view-component=\"true\" href=\"/ripienaar\">\n",
       "             R.I.Pienaar\n",
       " </a> </h1>,\n",
       " <h1 class=\"h3 lh-condensed\">\n",
       " <a class=\"Link\" data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"TRENDING_DEVELOPERS_PAGE\",\"click_target\":\"OWNER\",\"click_visual_representation\":\"TRENDING_DEVELOPER\",\"actor_id\":null,\"record_id\":7413593,\"originating_url\":\"https://github.com/trending/developers\",\"user_id\":null}}' data-hydro-click-hmac=\"5a21d82b36cbfc270fd68532b88d06a8c190622662a84592756a6bcc97b46142\" data-view-component=\"true\" href=\"/a8m\">\n",
       "             Ariel Mashraki\n",
       " </a> </h1>,\n",
       " <h1 class=\"h3 lh-condensed\">\n",
       " <a class=\"Link\" data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"TRENDING_DEVELOPERS_PAGE\",\"click_target\":\"OWNER\",\"click_visual_representation\":\"TRENDING_DEVELOPER\",\"actor_id\":null,\"record_id\":999588,\"originating_url\":\"https://github.com/trending/developers\",\"user_id\":null}}' data-hydro-click-hmac=\"9cf53cb4ca78b632d4389ff2edb8e2bd5aed2fc8ee1ea79757ba1da3814f0d66\" data-view-component=\"true\" href=\"/nolimits4web\">\n",
       "             Vladimir Kharlampidi\n",
       " </a> </h1>,\n",
       " <h1 class=\"h3 lh-condensed\">\n",
       " <a class=\"Link\" data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"TRENDING_DEVELOPERS_PAGE\",\"click_target\":\"OWNER\",\"click_visual_representation\":\"TRENDING_DEVELOPER\",\"actor_id\":null,\"record_id\":23632352,\"originating_url\":\"https://github.com/trending/developers\",\"user_id\":null}}' data-hydro-click-hmac=\"08e73edf239edea1280c4607a24ae253b10224a7b99d0f0e4e347cafaf062623\" data-view-component=\"true\" href=\"/lightaime\">\n",
       "             Guohao Li\n",
       " </a> </h1>,\n",
       " <h1 class=\"h3 lh-condensed\">\n",
       " <a class=\"Link\" data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"TRENDING_DEVELOPERS_PAGE\",\"click_target\":\"OWNER\",\"click_visual_representation\":\"TRENDING_DEVELOPER\",\"actor_id\":null,\"record_id\":685609,\"originating_url\":\"https://github.com/trending/developers\",\"user_id\":null}}' data-hydro-click-hmac=\"7a0b5bcb815211b30d4ba781a925ee5a924c031abe733744009ed7fb78598570\" data-view-component=\"true\" href=\"/NachoSoto\">\n",
       "             NachoSoto\n",
       " </a> </h1>,\n",
       " <h1 class=\"h3 lh-condensed\">\n",
       " <a class=\"Link\" data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"TRENDING_DEVELOPERS_PAGE\",\"click_target\":\"OWNER\",\"click_visual_representation\":\"TRENDING_DEVELOPER\",\"actor_id\":null,\"record_id\":8060102,\"originating_url\":\"https://github.com/trending/developers\",\"user_id\":null}}' data-hydro-click-hmac=\"298f65698f2d852d1de5f459abd36ed12b5f5edbaa364768d0736dcafafc26b0\" data-view-component=\"true\" href=\"/ErickWendel\">\n",
       "             Erick Wendel\n",
       " </a> </h1>,\n",
       " <h1 class=\"h3 lh-condensed\">\n",
       " <a class=\"Link\" data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"TRENDING_DEVELOPERS_PAGE\",\"click_target\":\"OWNER\",\"click_visual_representation\":\"TRENDING_DEVELOPER\",\"actor_id\":null,\"record_id\":17034772,\"originating_url\":\"https://github.com/trending/developers\",\"user_id\":null}}' data-hydro-click-hmac=\"384969277c63130e8ecce7cc427c06e03026df2fffb8eebbccc39fa3a91e1326\" data-view-component=\"true\" href=\"/jonatanklosko\">\n",
       "             Jonatan Kłosko\n",
       " </a> </h1>,\n",
       " <h1 class=\"h3 lh-condensed\">\n",
       " <a class=\"Link\" data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"TRENDING_DEVELOPERS_PAGE\",\"click_target\":\"OWNER\",\"click_visual_representation\":\"TRENDING_DEVELOPER\",\"actor_id\":null,\"record_id\":11146458,\"originating_url\":\"https://github.com/trending/developers\",\"user_id\":null}}' data-hydro-click-hmac=\"4ff2ae6aa2f4e218724339aa7636a825db581048b873f2210b35d0ee714beeff\" data-view-component=\"true\" href=\"/MilosKozak\">\n",
       "             Milos Kozak\n",
       " </a> </h1>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devs = soup.find_all(\"h1\", {\"class\": \"h3 lh-condensed\"}) \n",
    "devs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Meng Zhang'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "developers_name = devs[0].getText().replace(\"\\n\", \"\").strip()\n",
    "developers_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Meng Zhang',\n",
       " 'Azure SDK Bot',\n",
       " 'Olivier Halligon',\n",
       " 'Oscar Dowson',\n",
       " 'Fatih Arslan',\n",
       " 'Alon Zakai',\n",
       " 'Adrian Wälchli',\n",
       " 'Vectorized',\n",
       " 'Jonny Burger',\n",
       " 'dennis zhuang',\n",
       " 'Rui Chen',\n",
       " 'Charlie Marsh',\n",
       " 'Jason Hall',\n",
       " 'Shahed Nasser',\n",
       " 'Joshua Liebow-Feeser',\n",
       " 'pngwn',\n",
       " 'Stas Bekman',\n",
       " 'R.I.Pienaar',\n",
       " 'Ariel Mashraki',\n",
       " 'Vladimir Kharlampidi',\n",
       " 'Guohao Li',\n",
       " 'NachoSoto',\n",
       " 'Erick Wendel',\n",
       " 'Jonatan Kłosko',\n",
       " 'Milos Kozak']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devs_all = [i.getText().replace(\"\\n\", \"\").strip() for i in devs]\n",
    "devs_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wsxiaoys',\n",
       " 'azure-sdk',\n",
       " 'AliSoftware',\n",
       " 'odow',\n",
       " 'fatih',\n",
       " 'kripken',\n",
       " 'awaelchli',\n",
       " 'Vectorized',\n",
       " 'JonnyBurger',\n",
       " 'killme2008',\n",
       " 'chenrui333',\n",
       " 'charliermarsh',\n",
       " 'imjasonh',\n",
       " 'shahednasser',\n",
       " 'joshlf',\n",
       " 'pngwn',\n",
       " 'stas00',\n",
       " 'ripienaar',\n",
       " 'a8m',\n",
       " 'nolimits4web',\n",
       " 'lightaime',\n",
       " 'NachoSoto',\n",
       " 'ErickWendel',\n",
       " 'jonatanklosko',\n",
       " 'MilosKozak']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "nickname = soup.find_all(\"p\", {\"class\": \"f4 text-normal mb-1\"}) \n",
    "\n",
    "nickname_clean = nickname[0].getText().replace(\"\\n\", \"\").strip()\n",
    "\n",
    "nickname_clean\n",
    "\n",
    "all_nicknames = [i.getText().replace(\"\\n\", \"\").strip() for i in nickname]\n",
    "all_nicknames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the names of the trending developers retrieved in the previous step.\n",
    "\n",
    "Your output should be a Python list of developer names. Each name should not contain any html tag.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Find out the html tag and class names used for the developer names. You can achieve this using Chrome DevTools.\n",
    "\n",
    "1. Use BeautifulSoup to extract all the html elements that contain the developer names.\n",
    "\n",
    "1. Use string manipulation techniques to replace whitespaces and linebreaks (i.e. `\\n`) in the *text* of each html element. Use a list to store the clean names.\n",
    "\n",
    "1. Print the list of names.\n",
    "\n",
    "Your output should look like below:\n",
    "\n",
    "```\n",
    "['trimstray (@trimstray)',\n",
    " 'joewalnes (JoeWalnes)',\n",
    " 'charlax (Charles-AxelDein)',\n",
    " 'ForrestKnight (ForrestKnight)',\n",
    " 'revery-ui (revery-ui)',\n",
    " 'alibaba (Alibaba)',\n",
    " 'Microsoft (Microsoft)',\n",
    " 'github (GitHub)',\n",
    " 'facebook (Facebook)',\n",
    " 'boazsegev (Bo)',\n",
    " 'google (Google)',\n",
    " 'cloudfetch',\n",
    " 'sindresorhus (SindreSorhus)',\n",
    " 'tensorflow',\n",
    " 'apache (TheApacheSoftwareFoundation)',\n",
    " 'DevonCrawford (DevonCrawford)',\n",
    " 'ARMmbed (ArmMbed)',\n",
    " 'vuejs (vuejs)',\n",
    " 'fastai (fast.ai)',\n",
    " 'QiShaoXuan (Qi)',\n",
    " 'joelparkerhenderson (JoelParkerHenderson)',\n",
    " 'torvalds (LinusTorvalds)',\n",
    " 'CyC2018',\n",
    " 'komeiji-satori (神楽坂覚々)',\n",
    " 'script-8']\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Meng Zhang (wsxiaoys)',\n",
       " 'Azure SDK Bot (azure-sdk)',\n",
       " 'Olivier Halligon (AliSoftware)',\n",
       " 'Oscar Dowson (odow)',\n",
       " 'Fatih Arslan (fatih)',\n",
       " 'Alon Zakai (kripken)',\n",
       " 'Adrian Wälchli (awaelchli)',\n",
       " 'Vectorized (Vectorized)',\n",
       " 'Jonny Burger (JonnyBurger)',\n",
       " 'dennis zhuang (killme2008)',\n",
       " 'Rui Chen (chenrui333)',\n",
       " 'Charlie Marsh (charliermarsh)',\n",
       " 'Jason Hall (imjasonh)',\n",
       " 'Shahed Nasser (shahednasser)',\n",
       " 'Joshua Liebow-Feeser (joshlf)',\n",
       " 'pngwn (pngwn)',\n",
       " 'Stas Bekman (stas00)',\n",
       " 'R.I.Pienaar (ripienaar)',\n",
       " 'Ariel Mashraki (a8m)',\n",
       " 'Vladimir Kharlampidi (nolimits4web)',\n",
       " 'Guohao Li (lightaime)',\n",
       " 'NachoSoto (NachoSoto)',\n",
       " 'Erick Wendel (ErickWendel)',\n",
       " 'Jonatan Kłosko (jonatanklosko)',\n",
       " 'Milos Kozak (MilosKozak)']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devs_completed = [i + \" \" + \"(\"+ j + \")\" for i, j in list(zip(devs_all, all_nicknames))]\n",
    "devs_completed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the trending Python repositories in GitHub\n",
    "\n",
    "The steps to solve this problem is similar to the previous one except that you need to find out the repository names instead of developer names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://github.com/trending/python?since=daily'\n",
    "res = requests.get('https://github.com/trending/python?since=daily')\n",
    "html = res.content\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "repos = soup.find_all(\"h2\", {\"class\": \"h3 lh-condensed\"}) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'public-apis /      public-apis'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_text = repos[0].getText().replace(\"\\n\", \"\").strip()\n",
    "repo_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['public-apis /      public-apis',\n",
       " 'SUDO-AI-3D /      zero123plus',\n",
       " 's0md3v /      roop',\n",
       " 'xlang-ai /      OpenAgents',\n",
       " 'AI-Citizen /      SolidGPT',\n",
       " 'psf /      black',\n",
       " 'THUDM /      AgentTuning',\n",
       " 'bregman-arie /      devops-exercises',\n",
       " 'pyg-team /      pytorch_geometric',\n",
       " 'bytedance /      SALMONN',\n",
       " 'donnemartin /      system-design-primer',\n",
       " 'N1k0la-T /      CVE-2023-36745',\n",
       " 'firmai /      financial-machine-learning',\n",
       " 'w-okada /      voice-changer',\n",
       " 'horizon3ai /      CVE-2023-34051',\n",
       " 'kyleskom /      NBA-Machine-Learning-Sports-Betting',\n",
       " 'facebookresearch /      seamless_communication',\n",
       " 'LAION-AI /      Open-Assistant',\n",
       " 'danswer-ai /      danswer',\n",
       " 'XingangPan /      DragGAN',\n",
       " 'haotian-liu /      LLaVA',\n",
       " 'iterative /      dvc',\n",
       " 'mckinsey /      vizro',\n",
       " 'astral-sh /      ruff-pre-commit',\n",
       " 'eosphoros-ai /      DB-GPT']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repos_all = [i.getText().replace(\"\\n\", \"\").strip() for i in repos]\n",
    "repos_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display all the image links from Walt Disney wikipedia page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://en.wikipedia.org/wiki/Walt_Disney'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get('https://en.wikipedia.org/wiki/Walt_Disney')\n",
    "html = res.content\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/wiki/File:Walt_Disney_1946.JPG',\n",
       " '/wiki/File:Walt_Disney_1942_signature.svg',\n",
       " '/wiki/File:Walt_Disney_Birthplace_Exterior_Hermosa_Chicago_Illinois.jpg',\n",
       " '/wiki/File:Walt_Disney_envelope_ca._1921.jpg',\n",
       " '/wiki/File:Steamboat-willie.jpg',\n",
       " '/wiki/File:Walt_Disney_Snow_white_1937_trailer_screenshot_(13).jpg',\n",
       " '/wiki/File:Disney_drawing_goofy.jpg',\n",
       " '/wiki/File:WaltDisneyplansDisneylandDec1954.jpg',\n",
       " '/wiki/File:Walt_disney_portrait_right.jpg',\n",
       " '/wiki/File:Walt_Disney_Grave.JPG',\n",
       " '/wiki/File:DisneySchiphol1951.jpg',\n",
       " '/wiki/File:Disney1968.jpg',\n",
       " '/wiki/File:Disney_Oscar_1953_(cropped).jpg',\n",
       " '/wiki/File:Disneyland_Resort_logo.svg',\n",
       " '/wiki/File:Animation_disc.svg',\n",
       " '/wiki/File:Magic_Kingdom_castle.jpg',\n",
       " '/wiki/File:Blank_television_set.svg']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = soup.findAll(\"a\", {\"class\", \"mw-file-description\"})\n",
    "all_href = [i.get(\"href\") for i in links]\n",
    "all_href"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve an arbitary Wikipedia page of \"Python\" and create a list of links on that page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url ='https://en.wikipedia.org/wiki/Python' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get('https://en.wikipedia.org/wiki/Python' )\n",
    "html = res.content\n",
    "soup = BeautifulSoup(html, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&utm_medium=sidebar&utm_campaign=C13_en.wikipedia.org&uselang=en',\n",
       " 'https://af.wikipedia.org/wiki/Python',\n",
       " 'https://als.wikipedia.org/wiki/Python',\n",
       " 'https://ar.wikipedia.org/wiki/%D8%A8%D8%A7%D9%8A%D8%AB%D9%88%D9%86_(%D8%AA%D9%88%D8%B6%D9%8A%D8%AD)',\n",
       " 'https://az.wikipedia.org/wiki/Python_(d%C9%99qiql%C9%99%C5%9Fdirm%C9%99)',\n",
       " 'https://bn.wikipedia.org/wiki/%E0%A6%AA%E0%A6%BE%E0%A6%87%E0%A6%A5%E0%A6%A8_(%E0%A6%A6%E0%A7%8D%E0%A6%AC%E0%A7%8D%E0%A6%AF%E0%A6%B0%E0%A7%8D%E0%A6%A5%E0%A6%A4%E0%A6%BE_%E0%A6%A8%E0%A6%BF%E0%A6%B0%E0%A6%B8%E0%A6%A8)',\n",
       " 'https://be.wikipedia.org/wiki/Python',\n",
       " 'https://bg.wikipedia.org/wiki/%D0%9F%D0%B8%D1%82%D0%BE%D0%BD_(%D0%BF%D0%BE%D1%8F%D1%81%D0%BD%D0%B5%D0%BD%D0%B8%D0%B5)',\n",
       " 'https://cs.wikipedia.org/wiki/Python_(rozcestn%C3%ADk)',\n",
       " 'https://da.wikipedia.org/wiki/Python',\n",
       " 'https://de.wikipedia.org/wiki/Python',\n",
       " 'https://eo.wikipedia.org/wiki/Pitono_(apartigilo)',\n",
       " 'https://eu.wikipedia.org/wiki/Python_(argipena)',\n",
       " 'https://fa.wikipedia.org/wiki/%D9%BE%D8%A7%DB%8C%D8%AA%D9%88%D9%86',\n",
       " 'https://fr.wikipedia.org/wiki/Python',\n",
       " 'https://ko.wikipedia.org/wiki/%ED%8C%8C%EC%9D%B4%EC%84%A0',\n",
       " 'https://hr.wikipedia.org/wiki/Python_(razdvojba)',\n",
       " 'https://io.wikipedia.org/wiki/Pitono',\n",
       " 'https://id.wikipedia.org/wiki/Python',\n",
       " 'https://ia.wikipedia.org/wiki/Python_(disambiguation)',\n",
       " 'https://is.wikipedia.org/wiki/Python_(a%C3%B0greining)',\n",
       " 'https://it.wikipedia.org/wiki/Python_(disambigua)',\n",
       " 'https://he.wikipedia.org/wiki/%D7%A4%D7%99%D7%AA%D7%95%D7%9F',\n",
       " 'https://ka.wikipedia.org/wiki/%E1%83%9E%E1%83%98%E1%83%97%E1%83%9D%E1%83%9C%E1%83%98_(%E1%83%9B%E1%83%A0%E1%83%90%E1%83%95%E1%83%90%E1%83%9A%E1%83%9B%E1%83%9C%E1%83%98%E1%83%A8%E1%83%95%E1%83%9C%E1%83%94%E1%83%9A%E1%83%9D%E1%83%95%E1%83%90%E1%83%9C%E1%83%98)',\n",
       " 'https://kg.wikipedia.org/wiki/Mboma_(nyoka)',\n",
       " 'https://la.wikipedia.org/wiki/Python_(discretiva)',\n",
       " 'https://lb.wikipedia.org/wiki/Python',\n",
       " 'https://hu.wikipedia.org/wiki/Python_(egy%C3%A9rtelm%C5%B1s%C3%ADt%C5%91_lap)',\n",
       " 'https://mr.wikipedia.org/wiki/%E0%A4%AA%E0%A4%BE%E0%A4%AF%E0%A4%A5%E0%A5%89%E0%A4%A8_(%E0%A4%86%E0%A4%9C%E0%A5%8D%E0%A4%9E%E0%A4%BE%E0%A4%B5%E0%A4%B2%E0%A5%80_%E0%A4%AD%E0%A4%BE%E0%A4%B7%E0%A4%BE)',\n",
       " 'https://nl.wikipedia.org/wiki/Python',\n",
       " 'https://ja.wikipedia.org/wiki/%E3%83%91%E3%82%A4%E3%82%BD%E3%83%B3',\n",
       " 'https://no.wikipedia.org/wiki/Pyton',\n",
       " 'https://pl.wikipedia.org/wiki/Pyton',\n",
       " 'https://pt.wikipedia.org/wiki/Python_(desambigua%C3%A7%C3%A3o)',\n",
       " 'https://ru.wikipedia.org/wiki/Python_(%D0%B7%D0%BD%D0%B0%D1%87%D0%B5%D0%BD%D0%B8%D1%8F)',\n",
       " 'https://sk.wikipedia.org/wiki/Python',\n",
       " 'https://sr.wikipedia.org/wiki/%D0%9F%D0%B8%D1%82%D0%BE%D0%BD_(%D0%B2%D0%B8%D1%88%D0%B5%D0%B7%D0%BD%D0%B0%D1%87%D0%BD%D0%B0_%D0%BE%D0%B4%D1%80%D0%B5%D0%B4%D0%BD%D0%B8%D1%86%D0%B0)',\n",
       " 'https://sh.wikipedia.org/wiki/Python',\n",
       " 'https://fi.wikipedia.org/wiki/Python',\n",
       " 'https://sv.wikipedia.org/wiki/Pyton',\n",
       " 'https://th.wikipedia.org/wiki/%E0%B9%84%E0%B8%9E%E0%B8%97%E0%B8%AD%E0%B8%99',\n",
       " 'https://tr.wikipedia.org/wiki/Python_(anlam_ayr%C4%B1m%C4%B1)',\n",
       " 'https://uk.wikipedia.org/wiki/%D0%9F%D1%96%D1%84%D0%BE%D0%BD',\n",
       " 'https://ur.wikipedia.org/wiki/%D9%BE%D8%A7%D8%A6%DB%8C%D8%AA%DA%BE%D9%88%D9%86',\n",
       " 'https://vi.wikipedia.org/wiki/Python',\n",
       " 'https://zh.wikipedia.org/wiki/Python_(%E6%B6%88%E6%AD%A7%E4%B9%89)',\n",
       " 'https://www.wikidata.org/wiki/Special:EntityPage/Q747452#sitelinks-wikipedia',\n",
       " '/w/index.php?title=Special:UrlShortener&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FPython',\n",
       " 'https://www.wikidata.org/wiki/Special:EntityPage/Q747452',\n",
       " 'https://commons.wikimedia.org/wiki/Category:Python',\n",
       " 'https://en.wiktionary.org/wiki/Python',\n",
       " 'https://en.wiktionary.org/wiki/python',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Special:WhatLinksHere/Python&namespace=0',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Python&oldid=1180369030',\n",
       " 'https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Privacy_policy',\n",
       " 'https://foundation.wikimedia.org/wiki/Special:MyLanguage/Universal_Code_of_Conduct',\n",
       " 'https://developer.wikimedia.org',\n",
       " 'https://stats.wikimedia.org/#/en.wikipedia.org',\n",
       " 'https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Cookie_statement',\n",
       " 'https://wikimediafoundation.org/',\n",
       " 'https://www.mediawiki.org/']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def links(url):\n",
    "\n",
    "    res = requests.get(url)\n",
    "    html = res.content\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    links_list = soup.find_all(\"a\")\n",
    "    links = [i.get(\"href\") for i in links_list]\n",
    "    return [i for i in links if \"http\" in i]\n",
    "\n",
    "links('https://en.wikipedia.org/wiki/Python')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Titles that have changed in the United States Code since its last release point "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'http://uscode.house.gov/download/download.shtml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get('http://uscode.house.gov/download/download.shtml')\n",
    "html = res.content\n",
    "soup = BeautifulSoup(html, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Title 20 - Education', \"Title 38 - Veterans' Benefits ٭\"]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_list = soup.find_all(\"div\", {\"class\", \"usctitlechanged\"})\n",
    "book_clean = book_list[0].getText().replace(\"\\n\", \"\").strip()\n",
    "book_clean\n",
    "all_books = [i.getText().replace(\"\\n\", \"\").strip() for i in book_list]\n",
    "all_books\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  20 latest earthquakes info (date, time, latitude, longitude and region name) by the EMSC as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://www.emsc-csem.org/Earthquake/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get('https://www.emsc-csem.org/Earthquake/')\n",
    "html = res.content\n",
    "soup = BeautifulSoup(html, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_list = soup.find_all(\"div\", {\"class\", \"usctitlechanged\"})\n",
    "book_clean = book_list[0].getText().replace(\"\\n\", \"\").strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS QUESTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the date, days, title, city, country of next 25 hackathon events as a Pandas dataframe table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url ='https://hackevents.co/hackathons'\n",
    "url_hack = 'https://hackevents.co/search/anything/anywhere/anytime' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List all language names and number of related articles in the order they appear in wikipedia.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://www.wikipedia.org/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A list with the different kind of datasets available in data.gov.uk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://data.gov.uk/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 languages by number of native speakers stored in a Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMDB's Top 250 data (movie name, Initial release, director name and stars) as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "url = 'https://www.imdb.com/chart/top'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
